# backend/patterns/reverse.py - è¶…è»½é‡ãƒ»ãƒ¡ãƒ¢ãƒªã‚¹ãƒ‘ã‚¤ã‚¯å¯¾ç­–ç‰ˆï¼ˆ512MBåˆ¶é™å¯¾å¿œï¼‰
import numpy as np
import cv2
from PIL import Image
import gc
import sys
from core.image_utils import ensure_array, ensure_pil

# **ãƒ¡ãƒ¢ãƒªåˆ¶é™å¯¾å¿œ: ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š**
MAX_IMAGE_DIMENSION = 1024  # æœ€å¤§ã‚µã‚¤ã‚ºã‚’1024pxã«åˆ¶é™
MEMORY_SAFE_SIZE = 800      # å®‰å…¨ã‚µã‚¤ã‚º
CHUNK_SIZE = 256           # ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚µã‚¤ã‚º

def extract_hidden_image_from_moire(moire_img, method="fourier_analysis", enhancement_level=2.0):
    """
    ãƒ¢ã‚¢ãƒ¬åŠ¹æœç”»åƒã‹ã‚‰éš ã—ç”»åƒã‚’æŠ½å‡ºï¼ˆè¶…è»½é‡ãƒ»ãƒ¡ãƒ¢ãƒªã‚¹ãƒ‘ã‚¤ã‚¯å¯¾ç­–ç‰ˆï¼‰
    512MBåˆ¶é™ç’°å¢ƒã§ã‚‚å®‰å…¨ã«å‹•ä½œã™ã‚‹ã‚ˆã†æœ€é©åŒ–
    """
    # **ãƒ¡ãƒ¢ãƒªå¯¾ç­–1: å³åº§ã®ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³**
    gc.collect()
    
    # **ãƒ¡ãƒ¢ãƒªå¯¾ç­–2: å…¥åŠ›ç”»åƒã®è»½é‡åŒ–**
    moire_array = prepare_lightweight_image(moire_img)
    
    try:
        if method == "pattern_subtraction":
            # æœ€ã‚‚ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªæ–¹æ³•ã‚’å„ªå…ˆ
            return extract_via_pattern_subtraction_ultra_light(moire_array, enhancement_level)
        elif method == "frequency_filtering":
            return extract_via_frequency_filtering_ultra_light(moire_array, enhancement_level)
        elif method == "adaptive_detection":
            return extract_via_adaptive_detection_ultra_light(moire_array, enhancement_level)
        else:  # fourier_analysis
            return extract_via_fourier_analysis_ultra_light(moire_array, enhancement_level)
    finally:
        # **ãƒ¡ãƒ¢ãƒªå¯¾ç­–3: å‡¦ç†å¾Œã®å³åº§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—**
        del moire_array
        gc.collect()

def prepare_lightweight_image(moire_img):
    """
    ç”»åƒã‚’è»½é‡åŒ–ã—ã¦æº–å‚™ï¼ˆãƒ¡ãƒ¢ãƒªã‚¹ãƒ‘ã‚¤ã‚¯é˜²æ­¢ï¼‰
    """
    # **è»½é‡åŒ–1: é…åˆ—å¤‰æ›ã®æœ€é©åŒ–**
    if isinstance(moire_img, np.ndarray):
        img_array = moire_img
    else:
        img_array = np.array(moire_img, dtype=np.uint8)  # æœ€åˆã‹ã‚‰uint8
    
    height, width = img_array.shape[:2]
    
    # **è»½é‡åŒ–2: ç©æ¥µçš„ãªã‚µã‚¤ã‚ºåˆ¶é™**
    if max(height, width) > MAX_IMAGE_DIMENSION:
        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ä¿æŒã§ãƒªã‚µã‚¤ã‚º
        scale = MAX_IMAGE_DIMENSION / max(height, width)
        new_height = int(height * scale)
        new_width = int(width * scale)
        
        # OpenCVã§é«˜é€Ÿãƒªã‚µã‚¤ã‚ºï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ï¼‰
        img_array = cv2.resize(img_array, (new_width, new_height), interpolation=cv2.INTER_AREA)
        
        print(f"ğŸ“ Image resized to {new_width}x{new_height} for memory efficiency")
    
    # **è»½é‡åŒ–3: ã•ã‚‰ã«å¤§ãã„å ´åˆã®ç·Šæ€¥ã‚µã‚¤ã‚ºåˆ¶é™**
    if max(img_array.shape[:2]) > MEMORY_SAFE_SIZE:
        scale = MEMORY_SAFE_SIZE / max(img_array.shape[:2])
        new_h = int(img_array.shape[0] * scale)
        new_w = int(img_array.shape[1] * scale)
        img_array = cv2.resize(img_array, (new_w, new_h), interpolation=cv2.INTER_AREA)
        print(f"âš ï¸ Emergency resize to {new_w}x{new_h} for memory safety")
    
    return img_array

def extract_via_pattern_subtraction_ultra_light(moire_array, enhancement_level=2.0):
    """
    ãƒ‘ã‚¿ãƒ¼ãƒ³æ¸›ç®—ã«ã‚ˆã‚‹æŠ½å‡ºï¼ˆè¶…è»½é‡ç‰ˆï¼‰- æœ€ã‚‚ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªæ–¹æ³•
    """
    height, width = moire_array.shape[:2]
    
    # **è»½é‡åŒ–1: ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›ã®æœ€é©åŒ–**
    if len(moire_array.shape) == 3:
        gray = cv2.cvtColor(moire_array, cv2.COLOR_RGB2GRAY)
        del moire_array  # å³åº§ã«å‰Šé™¤
        gc.collect()
    else:
        gray = moire_array.copy()
        del moire_array
    
    # **è»½é‡åŒ–2: å°ã•ãªã‚µãƒ³ãƒ—ãƒ«ã§ã®ç›¸é–¢è¨ˆç®—**
    sample_size = min(64, height // 8, width // 8)  # ã•ã‚‰ã«å°ã•ãªã‚µãƒ³ãƒ—ãƒ«
    sample_y = height // 4
    sample_x = width // 4
    
    gray_sample = gray[sample_y:sample_y+sample_size, sample_x:sample_x+sample_size].astype(np.float32)
    
    # **è»½é‡åŒ–3: åŠ¹ç‡çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆï¼ˆãƒ¡ãƒ¢ãƒªã‚’ä½¿ã„å›ã—ï¼‰**
    y_pattern = np.arange(sample_size, dtype=np.uint8).reshape(-1, 1)
    h_pattern_sample = np.broadcast_to((y_pattern % 2) * 255, (sample_size, sample_size)).astype(np.float32)
    
    x_pattern = np.arange(sample_size, dtype=np.uint8).reshape(1, -1)
    v_pattern_sample = np.broadcast_to((x_pattern % 2) * 255, (sample_size, sample_size)).astype(np.float32)
    
    # **è»½é‡åŒ–4: ç›¸é–¢è¨ˆç®—ã®åŠ¹ç‡åŒ–**
    h_corr = np.corrcoef(gray_sample.flatten(), h_pattern_sample.flatten())[0, 1]
    v_corr = np.corrcoef(gray_sample.flatten(), v_pattern_sample.flatten())[0, 1]
    
    # ä¸­é–“ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    del gray_sample, h_pattern_sample, v_pattern_sample
    gc.collect()
    
    # **è»½é‡åŒ–5: ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã«ã‚ˆã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³æ¸›ç®—**
    if abs(h_corr) > abs(v_corr):
        # æ°´å¹³ãƒ‘ã‚¿ãƒ¼ãƒ³
        pattern_type = "horizontal"
        correlation_strength = abs(h_corr)
    else:
        # å‚ç›´ãƒ‘ã‚¿ãƒ¼ãƒ³
        pattern_type = "vertical"
        correlation_strength = abs(v_corr)
    
    # **è»½é‡åŒ–6: ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªçµæœç”Ÿæˆ**
    result = process_in_chunks(gray, pattern_type, correlation_strength, enhancement_level)
    
    del gray
    gc.collect()
    
    # **è»½é‡åŒ–7: RGBå¤‰æ›ã®æœ€é©åŒ–**
    if len(result.shape) == 2:
        # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã®ã¾ã¾è¿”ã™ï¼ˆãƒ¡ãƒ¢ãƒªç¯€ç´„ï¼‰
        return result
    else:
        return result

def process_in_chunks(gray, pattern_type, correlation_strength, enhancement_level):
    """
    ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’åˆ¶é™
    """
    height, width = gray.shape
    result = np.zeros_like(gray, dtype=np.uint8)
    
    # **ãƒãƒ£ãƒ³ã‚¯å‡¦ç†: è¡Œã”ã¨ã«å‡¦ç†**
    chunk_height = min(CHUNK_SIZE, height)
    
    for start_y in range(0, height, chunk_height):
        end_y = min(start_y + chunk_height, height)
        chunk = gray[start_y:end_y].astype(np.float32)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆ
        if pattern_type == "horizontal":
            y_indices = np.arange(start_y, end_y).reshape(-1, 1)
            pattern_chunk = np.broadcast_to((y_indices % 2) * 255.0, chunk.shape)
        else:  # vertical
            x_indices = np.arange(width).reshape(1, -1)
            pattern_chunk = np.broadcast_to((x_indices % 2) * 255.0, chunk.shape)
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³æ¸›ç®—
        subtraction_strength = np.clip(correlation_strength * 0.6, 0.2, 0.7)
        difference = chunk - pattern_chunk * subtraction_strength
        
        # å¼·èª¿å‡¦ç†
        enhanced = difference * enhancement_level + 128
        result[start_y:end_y] = np.clip(enhanced, 0, 255).astype(np.uint8)
        
        # ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        del chunk, pattern_chunk, difference, enhanced
    
    return result

def extract_via_frequency_filtering_ultra_light(moire_array, enhancement_level=2.0):
    """
    å‘¨æ³¢æ•°ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆè¶…è»½é‡ç‰ˆï¼‰
    """
    height, width = moire_array.shape[:2]
    
    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
    if len(moire_array.shape) == 3:
        gray = cv2.cvtColor(moire_array, cv2.COLOR_RGB2GRAY)
        del moire_array
        gc.collect()
    else:
        gray = moire_array.copy()
        del moire_array
    
    # **è»½é‡åŒ–: å°ã•ãªã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º**
    kernel_size = max(3, min(height, width) // 300) | 1
    
    # ãƒ–ãƒ©ãƒ¼å‡¦ç†
    blurred = cv2.GaussianBlur(gray, (kernel_size, kernel_size), 0)
    
    # ã‚¨ãƒƒã‚¸æ¤œå‡º
    mean_intensity = np.mean(blurred)
    low_threshold = max(15, int(mean_intensity * 0.2))
    high_threshold = min(100, int(mean_intensity * 0.6))
    
    edges = cv2.Canny(blurred, low_threshold, high_threshold)
    del blurred
    
    # ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ãƒ¼æ¼”ç®—
    morph_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
    processed_edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, morph_kernel)
    del edges
    
    # ãƒã‚¹ã‚¯å‡¦ç†
    stripe_mask = (processed_edges > 0).astype(np.float32)
    del processed_edges
    
    # ãƒ–ãƒ©ãƒ¼
    smoothed_mask = cv2.GaussianBlur(stripe_mask, (5, 5), 0)
    del stripe_mask
    
    # çµæœç”Ÿæˆ
    hidden_mask = 1.0 - smoothed_mask
    result = gray.astype(np.float32) * hidden_mask * enhancement_level
    
    del gray, smoothed_mask, hidden_mask
    gc.collect()
    
    return np.clip(result, 0, 255).astype(np.uint8)

def extract_via_adaptive_detection_ultra_light(moire_array, enhancement_level=2.0):
    """
    é©å¿œçš„æ¤œå‡ºï¼ˆè¶…è»½é‡ç‰ˆï¼‰
    """
    height, width = moire_array.shape[:2]
    
    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
    if len(moire_array.shape) == 3:
        gray = cv2.cvtColor(moire_array, cv2.COLOR_RGB2GRAY)
        del moire_array
        gc.collect()
    else:
        gray = moire_array.copy()
        del moire_array
    
    # **è»½é‡åŒ–: å°ã•ãªã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º**
    window_size = max(5, min(height, width) // 150) | 1
    
    # å±€æ‰€çµ±è¨ˆè¨ˆç®—ï¼ˆè»½é‡ç‰ˆï¼‰
    kernel = np.ones((window_size, window_size), np.float32) / (window_size * window_size)
    local_mean = cv2.filter2D(gray.astype(np.float32), -1, kernel)
    
    # ç°¡æ˜“çš„ãªåˆ†æ•£è¨ˆç®—
    diff = gray.astype(np.float32) - local_mean
    local_variance = cv2.filter2D(diff ** 2, -1, kernel)
    local_std = np.sqrt(np.maximum(local_variance, 1.0))
    
    del diff, local_variance
    
    # é©å¿œçš„é–¾å€¤
    global_std = np.std(gray)
    adaptive_factor = np.clip(global_std / 60.0, 0.2, 1.2)
    adaptive_threshold = local_mean + local_std * adaptive_factor
    
    del local_mean, local_std
    
    # ãƒã‚¹ã‚¯ç”Ÿæˆ
    hidden_mask = (gray.astype(np.float32) > adaptive_threshold).astype(np.float32)
    del adaptive_threshold
    
    # çµæœç”Ÿæˆ
    result = gray.astype(np.float32) * hidden_mask * enhancement_level
    
    del gray, hidden_mask
    gc.collect()
    
    return np.clip(result, 0, 255).astype(np.uint8)

def extract_via_fourier_analysis_ultra_light(moire_array, enhancement_level=2.0):
    """
    ãƒ•ãƒ¼ãƒªã‚¨è§£æï¼ˆè¶…è»½é‡ç‰ˆï¼‰- æœ€å°é™ã®å®Ÿè£…
    """
    height, width = moire_array.shape[:2]
    
    # ã‚µã‚¤ã‚ºåˆ¶é™ã‚’ã•ã‚‰ã«å³ã—ã
    if max(height, width) > 512:
        scale = 512 / max(height, width)
        new_h = int(height * scale)
        new_w = int(width * scale)
        if len(moire_array.shape) == 3:
            resized = cv2.resize(moire_array, (new_w, new_h))
            gray = cv2.cvtColor(resized, cv2.COLOR_RGB2GRAY)
        else:
            gray = cv2.resize(moire_array, (new_w, new_h))
        del moire_array, resized
    else:
        if len(moire_array.shape) == 3:
            gray = cv2.cvtColor(moire_array, cv2.COLOR_RGB2GRAY)
            del moire_array
        else:
            gray = moire_array.copy()
            del moire_array
    
    gc.collect()
    
    # ç°¡æ˜“çš„ãªFFTå‡¦ç†
    try:
        f_transform = np.fft.fft2(gray.astype(np.float32))
        f_shift = np.fft.fftshift(f_transform)
        del f_transform
        
        # ç°¡æ˜“ãƒ•ã‚£ãƒ«ã‚¿
        h, w = gray.shape
        center_y, center_x = h // 2, w // 2
        radius = min(h, w) // 8
        
        y, x = np.ogrid[:h, :w]
        mask = ((x - center_x)**2 + (y - center_y)**2) <= radius**2
        
        filtered = f_shift * mask.astype(np.float32)
        del f_shift, mask
        
        # é€†FFT
        f_ishift = np.fft.ifftshift(filtered)
        img_back = np.abs(np.fft.ifft2(f_ishift))
        del filtered, f_ishift
        
        # æ­£è¦åŒ–
        img_min, img_max = np.min(img_back), np.max(img_back)
        if img_max > img_min:
            result = (img_back - img_min) / (img_max - img_min) * 255 * enhancement_level
        else:
            result = np.full_like(img_back, 128)
        
        del img_back
        
    except Exception as e:
        print(f"âš ï¸ FFT failed, using fallback: {e}")
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šå˜ç´”ãªå‡¦ç†
        result = gray.astype(np.float32) * enhancement_level
    
    del gray
    gc.collect()
    
    return np.clip(result, 0, 255).astype(np.uint8)

def enhance_extracted_image_optimized(extracted_img, method="histogram_equalization"):
    """
    æŠ½å‡ºã•ã‚ŒãŸéš ã—ç”»åƒã‚’å¼·èª¿ï¼ˆè¶…è»½é‡ç‰ˆï¼‰
    """
    if method == "histogram_equalization":
        if len(extracted_img.shape) == 3:
            # ãƒãƒ£ãƒ³ãƒãƒ«åˆ¥å‡¦ç†
            result = np.zeros_like(extracted_img)
            for i in range(3):
                result[:,:,i] = cv2.equalizeHist(extracted_img[:,:,i])
            return result
        else:
            return cv2.equalizeHist(extracted_img)
    
    elif method == "clahe":
        # è»½é‡CLAHEè¨­å®š
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))
        
        if len(extracted_img.shape) == 3:
            result = np.zeros_like(extracted_img)
            for i in range(3):
                result[:,:,i] = clahe.apply(extracted_img[:,:,i])
            return result
        else:
            return clahe.apply(extracted_img)
    
    elif method == "gamma_correction":
        # è»½é‡ã‚¬ãƒ³ãƒè£œæ­£
        gamma = 0.7
        normalized = extracted_img.astype(np.float32) / 255.0
        corrected = np.power(normalized, gamma)
        result = (corrected * 255.0).astype(np.uint8)
        del normalized, corrected
        return result
    
    return extracted_img

# ã‚¨ã‚¤ãƒªã‚¢ã‚¹é–¢æ•°
def enhance_extracted_image(extracted_img, method="histogram_equalization"):
    """ã‚¨ã‚¤ãƒªã‚¢ã‚¹é–¢æ•°ï¼ˆäº’æ›æ€§ç¶­æŒï¼‰"""
    return enhance_extracted_image_optimized(extracted_img, method)
